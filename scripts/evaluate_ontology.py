#!/usr/bin/env python3
"""
Ontology Effectiveness Evaluator

ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
- ë™ì˜ì–´ í™•ì¥ íš¨ê³¼ (Synonym Expansion)
- ê³„ì¸µ í™•ì¥ íš¨ê³¼ (Hierarchy Expansion)
- Recall, Zero-result rate ì¸¡ì •

Usage:
    python scripts/evaluate_ontology.py
    python scripts/evaluate_ontology.py --verbose
"""

import logging
import sys
from dataclasses import dataclass, field
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.domain.ontology.loader import (
    ExpansionStrategy,
    OntologyLoader,
    get_config_for_strategy,
)

logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)


# =============================================================================
# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜
# =============================================================================

@dataclass
class TestCase:
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤"""
    query_term: str           # ê²€ìƒ‰ì–´ (í•œê¸€ ë˜ëŠ” ë¹„í‘œì¤€)
    category: str             # skills, positions, departments
    expected_canonical: str   # ê¸°ëŒ€ë˜ëŠ” ì •ê·œí™”ëœ ì´ë¦„
    description: str = ""     # í…ŒìŠ¤íŠ¸ ì„¤ëª…


# ë™ì˜ì–´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜)
SYNONYM_TEST_CASES = [
    # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
    TestCase("íŒŒì´ì¬", "skills", "Python", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("Python3", "skills", "Python", "ë²„ì „ í‘œê¸° ì •ê·œí™”"),
    TestCase("Py", "skills", "Python", "ì¶•ì•½í˜• í™•ì¥"),
    TestCase("ìë°”", "skills", "Java", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ìë°”ìŠ¤í¬ë¦½íŠ¸", "skills", "JavaScript", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("JS", "skills", "JavaScript", "ì¶•ì•½í˜• í™•ì¥"),
    TestCase("íƒ€ì…ìŠ¤í¬ë¦½íŠ¸", "skills", "TypeScript", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ê³ ë­", "skills", "Go", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),

    # AI/ML
    TestCase("ë¨¸ì‹ ëŸ¬ë‹", "skills", "ML", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ë”¥ëŸ¬ë‹", "skills", "Deep Learning", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ìì—°ì–´ì²˜ë¦¬", "skills", "NLP", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("í…ì„œí”Œë¡œìš°", "skills", "TensorFlow", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("íŒŒì´í† ì¹˜", "skills", "PyTorch", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),

    # í´ë¼ìš°ë“œ/ì¸í”„ë¼
    TestCase("ë„ì»¤", "skills", "Docker", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ì¿ ë²„ë„¤í‹°ìŠ¤", "skills", "Kubernetes", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("K8s", "skills", "Kubernetes", "ì¶•ì•½í˜• í™•ì¥"),
    TestCase("ì•„ë§ˆì¡´ ì›¹ ì„œë¹„ìŠ¤", "skills", "AWS", "ì „ì²´ ì´ë¦„ â†’ ì¶•ì•½"),
    TestCase("êµ¬ê¸€ í´ë¼ìš°ë“œ", "skills", "GCP", "ì „ì²´ ì´ë¦„ â†’ ì¶•ì•½"),

    # í”„ë ˆì„ì›Œí¬
    TestCase("ë¦¬ì•¡íŠ¸", "skills", "React", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),
    TestCase("ìŠ¤í”„ë§", "skills", "Spring", "í•œê¸€ â†’ ì˜ë¬¸ ë³€í™˜"),

    # ì§ê¸‰
    TestCase("Backend Developer", "positions", "Backend Developer", "ì˜ë¬¸ ì§ê¸‰"),
    TestCase("ì„œë²„ ê°œë°œì", "positions", "Backend Developer", "í•œê¸€ ì§ê¸‰ ë³€í™˜"),
    TestCase("ML Engineer", "positions", "ML Engineer", "ì˜ë¬¸ ì§ê¸‰"),

    # ë¶€ì„œ
    TestCase("Engineering", "departments", "Engineering", "ì˜ë¬¸ ë¶€ì„œ"),
    TestCase("ê°œë°œíŒ€", "departments", "Engineering", "í•œê¸€ ë¶€ì„œ ë³€í™˜"),
]


# =============================================================================
# í‰ê°€ ê²°ê³¼
# =============================================================================

@dataclass
class EvaluationResult:
    """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    test_case: TestCase
    expanded_terms: list[str]
    found_canonical: bool
    expansion_count: int


@dataclass
class EvaluationReport:
    """í‰ê°€ ë¦¬í¬íŠ¸"""
    results: list[EvaluationResult] = field(default_factory=list)

    @property
    def total_tests(self) -> int:
        return len(self.results)

    @property
    def successful_tests(self) -> int:
        return sum(1 for r in self.results if r.found_canonical)

    @property
    def recall(self) -> float:
        if self.total_tests == 0:
            return 0.0
        return self.successful_tests / self.total_tests

    @property
    def zero_result_rate_without_ontology(self) -> float:
        """ì˜¨í†¨ë¡œì§€ ì—†ì´ ê²€ìƒ‰í–ˆì„ ë•Œ ê²°ê³¼ 0ê±´ ë¹„ìœ¨"""
        # ì›ë³¸ ê²€ìƒ‰ì–´ì™€ expected_canonicalì´ ë‹¤ë¥¸ ê²½ìš°ë¥¼ zero-resultë¡œ ê°€ì •
        zero_results = sum(
            1 for r in self.results
            if r.test_case.query_term.lower() != r.test_case.expected_canonical.lower()
        )
        return zero_results / self.total_tests if self.total_tests > 0 else 0.0

    @property
    def zero_result_rate_with_ontology(self) -> float:
        """ì˜¨í†¨ë¡œì§€ë¡œ ê²€ìƒ‰í–ˆì„ ë•Œ ê²°ê³¼ 0ê±´ ë¹„ìœ¨"""
        zero_results = sum(1 for r in self.results if not r.found_canonical)
        return zero_results / self.total_tests if self.total_tests > 0 else 0.0

    @property
    def avg_expansion_count(self) -> float:
        if self.total_tests == 0:
            return 0.0
        return sum(r.expansion_count for r in self.results) / self.total_tests


# =============================================================================
# í‰ê°€ê¸°
# =============================================================================

class OntologyEvaluator:
    """ì˜¨í†¨ë¡œì§€ íš¨ê³¼ í‰ê°€ê¸°"""

    def __init__(self, ontology_dir: Path | str | None = None):
        self._loader = OntologyLoader(ontology_dir)

    def evaluate_synonym_expansion(
        self,
        test_cases: list[TestCase] | None = None,
        strategy: ExpansionStrategy = ExpansionStrategy.NORMAL,
    ) -> EvaluationReport:
        """ë™ì˜ì–´ í™•ì¥ íš¨ê³¼ í‰ê°€"""
        if test_cases is None:
            test_cases = SYNONYM_TEST_CASES

        config = get_config_for_strategy(strategy)
        report = EvaluationReport()

        for tc in test_cases:
            # ì˜¨í†¨ë¡œì§€ë¡œ í™•ì¥
            expanded = self._loader.expand_concept(tc.query_term, tc.category, config)

            # canonicalì´ í™•ì¥ ê²°ê³¼ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            found = any(
                term.lower() == tc.expected_canonical.lower()
                for term in expanded
            )

            result = EvaluationResult(
                test_case=tc,
                expanded_terms=expanded,
                found_canonical=found,
                expansion_count=len(expanded),
            )
            report.results.append(result)

        return report

    def print_report(self, report: EvaluationReport, verbose: bool = False) -> None:
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ì˜¨í†¨ë¡œì§€ íš¨ê³¼ ì¸¡ì • ë¦¬í¬íŠ¸")
        print("=" * 70)

        # ê°œë³„ ê²°ê³¼ (verbose ëª¨ë“œ)
        if verbose:
            print("\nğŸ“‹ ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print("-" * 70)
            for r in report.results:
                status = "âœ…" if r.found_canonical else "âŒ"
                print(f"  {status} '{r.test_case.query_term}' â†’ '{r.test_case.expected_canonical}'")
                print(f"     í™•ì¥ ê²°ê³¼ ({r.expansion_count}ê°œ): {r.expanded_terms[:5]}...")
                if not r.found_canonical:
                    print(f"     âš ï¸  Expected '{r.test_case.expected_canonical}' not found!")
                print()

        # ìš”ì•½ í†µê³„
        print("\nğŸ“ˆ ìš”ì•½ í†µê³„:")
        print("-" * 70)
        print(f"  ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {report.total_tests}")
        print(f"  ì„±ê³µ í…ŒìŠ¤íŠ¸ ìˆ˜: {report.successful_tests}")
        print(f"  í‰ê·  í™•ì¥ ê°œìˆ˜: {report.avg_expansion_count:.1f}")

        # í•µì‹¬ ë©”íŠ¸ë¦­
        print("\nğŸ¯ í•µì‹¬ ë©”íŠ¸ë¦­:")
        print("-" * 70)

        # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        print(f"  {'ë©”íŠ¸ë¦­':<35} {'ê°’':>10}")
        print(f"  {'-' * 35} {'-' * 10}")
        print(f"  {'Recall (ì˜¨í†¨ë¡œì§€ ON)':<35} {report.recall:>9.1%}")
        print(f"  {'Zero-result Rate (ì˜¨í†¨ë¡œì§€ OFF)':<35} {report.zero_result_rate_without_ontology:>9.1%}")
        print(f"  {'Zero-result Rate (ì˜¨í†¨ë¡œì§€ ON)':<35} {report.zero_result_rate_with_ontology:>9.1%}")

        # ê°œì„  íš¨ê³¼ ê³„ì‚°
        zero_result_reduction = (
            (report.zero_result_rate_without_ontology - report.zero_result_rate_with_ontology)
            / max(report.zero_result_rate_without_ontology, 0.01) * 100
        )

        # Recall ê°œì„ ìœ¨ (ì˜¨í†¨ë¡œì§€ ì—†ì„ ë•Œ vs ìˆì„ ë•Œ)
        baseline_recall = 1 - report.zero_result_rate_without_ontology
        recall_improvement = (
            (report.recall - baseline_recall) / max(baseline_recall, 0.01) * 100
            if baseline_recall > 0 else float("inf")
        )

        # ê°œì„  íš¨ê³¼
        print("\nğŸš€ ê°œì„  íš¨ê³¼:")
        print("-" * 70)
        print(f"  âœ¨ Zero-result Rate ê°ì†Œ: {zero_result_reduction:.1f}%")
        if recall_improvement != float("inf"):
            print(f"  âœ¨ Recall ê°œì„ ìœ¨: +{recall_improvement:.1f}%")
        else:
            print("  âœ¨ Recall ê°œì„ ìœ¨: âˆ (ê¸°ì¡´ ê²€ìƒ‰ ë¶ˆê°€ â†’ ê²€ìƒ‰ ê°€ëŠ¥)")

        if report.recall >= 0.9:
            print("  ğŸ‰ ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì´ ë§¤ìš° íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
        elif report.recall >= 0.7:
            print("  ğŸ‘ ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œì´ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            print("  âš ï¸  ì˜¨í†¨ë¡œì§€ ì»¤ë²„ë¦¬ì§€ë¥¼ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤
        failed = [r for r in report.results if not r.found_canonical]
        if failed:
            print(f"\nâŒ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ({len(failed)}ê±´):")
            print("-" * 70)
            for r in failed:
                print(f"  - '{r.test_case.query_term}' â†’ expected '{r.test_case.expected_canonical}'")
                print(f"    í™•ì¥ ê²°ê³¼: {r.expanded_terms}")

        print("\n" + "=" * 70)


# =============================================================================
# ë©”ì¸
# =============================================================================

def main() -> int:
    import argparse

    parser = argparse.ArgumentParser(description="ì˜¨í†¨ë¡œì§€ íš¨ê³¼ ì¸¡ì •")
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸ ê²°ê³¼ ì¶œë ¥",
    )
    parser.add_argument(
        "--strategy",
        choices=["strict", "normal", "broad"],
        default="normal",
        help="í™•ì¥ ì „ëµ (ê¸°ë³¸ê°’: normal)",
    )
    args = parser.parse_args()

    strategy_map = {
        "strict": ExpansionStrategy.STRICT,
        "normal": ExpansionStrategy.NORMAL,
        "broad": ExpansionStrategy.BROAD,
    }

    print("ğŸ” ì˜¨í†¨ë¡œì§€ íš¨ê³¼ ì¸¡ì • ì‹œì‘...")
    print(f"   ì „ëµ: {args.strategy.upper()}")

    evaluator = OntologyEvaluator()
    report = evaluator.evaluate_synonym_expansion(
        strategy=strategy_map[args.strategy]
    )
    evaluator.print_report(report, verbose=args.verbose)

    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œë„ ì €ì¥
    output_path = Path(__file__).parent.parent / "output" / "ontology_evaluation.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    import json
    result_data = {
        "strategy": args.strategy,
        "total_tests": report.total_tests,
        "successful_tests": report.successful_tests,
        "recall": report.recall,
        "zero_result_rate_without_ontology": report.zero_result_rate_without_ontology,
        "zero_result_rate_with_ontology": report.zero_result_rate_with_ontology,
        "avg_expansion_count": report.avg_expansion_count,
        "failed_cases": [
            {
                "query": r.test_case.query_term,
                "expected": r.test_case.expected_canonical,
                "expanded": r.expanded_terms,
            }
            for r in report.results if not r.found_canonical
        ],
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ë¨: {output_path}")

    return 0 if report.recall >= 0.7 else 1


if __name__ == "__main__":
    sys.exit(main())
