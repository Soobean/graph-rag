#!/usr/bin/env python3
"""
Ontology Validator

ì˜¨í†¨ë¡œì§€ YAML íŒŒì¼ì˜ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.
- ê³ ì•„ ìŠ¤í‚¬ íƒì§€ (schemaì—ë§Œ ìˆê³  synonymsì— ì—†ëŠ” ìŠ¤í‚¬)
- ì¤‘ë³µ canonical íƒì§€
- ìˆœí™˜ ì°¸ì¡° íƒì§€ (IS_A ê´€ê³„)
- ê¹¨ì§„ ì°¸ì¡° íƒì§€

Usage:
    python scripts/validate_ontology.py
    python scripts/validate_ontology.py --verbose
    python scripts/validate_ontology.py --fix  # ìë™ ìˆ˜ì • ì‹œë„ (í–¥í›„ êµ¬í˜„)
"""

import argparse
import logging
import sys
from dataclasses import dataclass, field
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.domain.ontology.loader import OntologyLoader

logging.basicConfig(
    level=logging.INFO,
    format="%(levelname)s: %(message)s",
)
logger = logging.getLogger(__name__)


@dataclass
class ValidationIssue:
    """ê²€ì¦ ì´ìŠˆ"""

    severity: str  # "error", "warning", "info"
    category: str  # "orphan", "duplicate", "circular", "broken"
    message: str
    location: str = ""  # íŒŒì¼:ë¼ì¸ ë˜ëŠ” ê°œë…ëª…


@dataclass
class ValidationReport:
    """ê²€ì¦ ë¦¬í¬íŠ¸"""

    issues: list[ValidationIssue] = field(default_factory=list)
    stats: dict[str, int] = field(default_factory=dict)

    @property
    def has_errors(self) -> bool:
        return any(i.severity == "error" for i in self.issues)

    @property
    def error_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == "error")

    @property
    def warning_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == "warning")

    def add_issue(
        self,
        severity: str,
        category: str,
        message: str,
        location: str = "",
    ) -> None:
        self.issues.append(
            ValidationIssue(
                severity=severity,
                category=category,
                message=message,
                location=location,
            )
        )

    def print_summary(self) -> None:
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ ì˜¨í†¨ë¡œì§€ ê²€ì¦ ë¦¬í¬íŠ¸")
        print("=" * 60)

        # í†µê³„
        print("\nğŸ“Š í†µê³„:")
        for key, value in self.stats.items():
            print(f"   - {key}: {value}")

        # ì—ëŸ¬
        errors = [i for i in self.issues if i.severity == "error"]
        if errors:
            print(f"\nğŸ”´ ì—ëŸ¬ ({len(errors)}ê±´):")
            for issue in errors:
                loc = f" [{issue.location}]" if issue.location else ""
                print(f"   - [{issue.category}]{loc} {issue.message}")

        # ê²½ê³ 
        warnings = [i for i in self.issues if i.severity == "warning"]
        if warnings:
            print(f"\nğŸŸ¡ ê²½ê³  ({len(warnings)}ê±´):")
            for issue in warnings:
                loc = f" [{issue.location}]" if issue.location else ""
                print(f"   - [{issue.category}]{loc} {issue.message}")

        # ì •ë³´
        infos = [i for i in self.issues if i.severity == "info"]
        if infos:
            print(f"\nğŸ”µ ì •ë³´ ({len(infos)}ê±´):")
            for issue in infos:
                loc = f" [{issue.location}]" if issue.location else ""
                print(f"   - [{issue.category}]{loc} {issue.message}")

        # ê²°ê³¼
        print("\n" + "-" * 60)
        if self.has_errors:
            print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {self.error_count}ê°œì˜ ì—ëŸ¬ ë°œê²¬")
        else:
            print("âœ… ê²€ì¦ í†µê³¼: ì‹¬ê°í•œ ë¬¸ì œ ì—†ìŒ")

        if self.warning_count > 0:
            print(f"   âš ï¸  {self.warning_count}ê°œì˜ ê²½ê³  í™•ì¸ í•„ìš”")

        print("=" * 60 + "\n")


class OntologyValidator:
    """
    ì˜¨í†¨ë¡œì§€ YAML ê²€ì¦ê¸°

    ê²€ì¦ í•­ëª©:
    1. ê³ ì•„ ìŠ¤í‚¬ (orphan): schemaì— ìˆì§€ë§Œ synonymsì— ì—†ëŠ” ìŠ¤í‚¬
    2. ì¤‘ë³µ canonical (duplicate): ë™ì¼í•œ canonicalì´ ì—¬ëŸ¬ ì—”íŠ¸ë¦¬ì— ì •ì˜ë¨
    3. ìˆœí™˜ ì°¸ì¡° (circular): IS_A ê´€ê³„ì—ì„œ ìˆœí™˜ ë°œìƒ
    4. ê¹¨ì§„ ì°¸ì¡° (broken): ì°¸ì¡°í•˜ëŠ” ìŠ¤í‚¬ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
    """

    def __init__(self, ontology_dir: Path | str | None = None):
        self._loader = OntologyLoader(ontology_dir)

    def validate_all(self) -> ValidationReport:
        """ì „ì²´ ê²€ì¦ ìˆ˜í–‰"""
        report = ValidationReport()

        # ë°ì´í„° ë¡œë“œ
        schema = self._loader.load_schema()
        synonyms = self._loader.load_synonyms()

        # í†µê³„ ìˆ˜ì§‘
        report.stats = self._collect_stats(schema, synonyms)

        # ê²€ì¦ ìˆ˜í–‰
        self._check_orphan_skills(schema, synonyms, report)
        self._check_duplicate_canonicals(synonyms, report)
        self._check_broken_references(schema, synonyms, report)
        self._check_missing_synonyms(schema, synonyms, report)

        return report

    def _collect_stats(
        self,
        schema: dict,
        synonyms: dict,
    ) -> dict[str, int]:
        """í†µê³„ ìˆ˜ì§‘"""
        stats = {}

        # ìŠ¤í‚¤ë§ˆ í†µê³„
        concepts = schema.get("concepts", {})
        skill_categories = concepts.get("SkillCategory", [])

        total_skills = 0
        total_categories = 0

        for category in skill_categories:
            if isinstance(category, dict):
                total_categories += 1
                total_skills += len(category.get("skills", []))

                for sub in category.get("subcategories", []):
                    total_categories += 1
                    total_skills += len(sub.get("skills", []))

        stats["ìŠ¤í‚¤ë§ˆ ì¹´í…Œê³ ë¦¬ ìˆ˜"] = total_categories
        stats["ìŠ¤í‚¤ë§ˆ ìŠ¤í‚¬ ìˆ˜"] = total_skills

        # ë™ì˜ì–´ í†µê³„
        for category_name, entries in synonyms.items():
            if category_name.startswith("_"):
                continue
            if isinstance(entries, dict):
                count = len(entries)
                stats[f"ë™ì˜ì–´ {category_name}"] = count

        return stats

    def _check_orphan_skills(
        self,
        schema: dict,
        synonyms: dict,
        report: ValidationReport,
    ) -> None:
        """ê³ ì•„ ìŠ¤í‚¬ ê²€ì‚¬: schemaì— ìˆì§€ë§Œ synonymsì— ì—†ëŠ” ìŠ¤í‚¬"""
        # ìŠ¤í‚¤ë§ˆì—ì„œ ëª¨ë“  ìŠ¤í‚¬ ì¶”ì¶œ
        schema_skills = self._extract_all_skills(schema)

        # ë™ì˜ì–´ì—ì„œ ëª¨ë“  canonical ë° alias ì¶”ì¶œ
        synonym_terms = self._extract_all_synonym_terms(synonyms, "skills")

        # ì°¨ì§‘í•©: ìŠ¤í‚¤ë§ˆì—ë§Œ ìˆëŠ” ìŠ¤í‚¬
        orphan_skills = schema_skills - synonym_terms

        for skill in sorted(orphan_skills):
            report.add_issue(
                severity="warning",
                category="orphan",
                message=f"'{skill}'ì´ schema.yamlì— ìˆì§€ë§Œ synonyms.yamlì— ì—†ìŠµë‹ˆë‹¤",
                location="schema.yaml",
            )

    def _check_duplicate_canonicals(
        self,
        synonyms: dict,
        report: ValidationReport,
    ) -> None:
        """ì¤‘ë³µ canonical ê²€ì‚¬"""
        for category_name, entries in synonyms.items():
            if category_name.startswith("_"):
                continue
            if not isinstance(entries, dict):
                continue

            # canonical â†’ ì›ë³¸ í‚¤ ë§¤í•‘
            canonical_map: dict[str, list[str]] = {}

            for main_term, info in entries.items():
                if not isinstance(info, dict):
                    continue
                canonical = info.get("canonical", main_term)
                canonical_lower = canonical.lower()

                if canonical_lower not in canonical_map:
                    canonical_map[canonical_lower] = []
                canonical_map[canonical_lower].append(main_term)

            # ì¤‘ë³µ ì²´í¬
            for canonical, sources in canonical_map.items():
                if len(sources) > 1:
                    report.add_issue(
                        severity="error",
                        category="duplicate",
                        message=f"'{canonical}' canonicalì´ ì—¬ëŸ¬ ì—”íŠ¸ë¦¬ì—ì„œ ì‚¬ìš©ë¨: {sources}",
                        location=f"synonyms.yaml/{category_name}",
                    )

    def _check_broken_references(
        self,
        schema: dict,
        synonyms: dict,
        report: ValidationReport,
    ) -> None:
        """ê¹¨ì§„ ì°¸ì¡° ê²€ì‚¬: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤í‚¬ ì°¸ì¡°"""
        # ëª¨ë“  ì •ì˜ëœ ìŠ¤í‚¬/ê°œë… ìˆ˜ì§‘
        all_defined = self._extract_all_skills(schema)
        all_synonyms = self._extract_all_synonym_terms(synonyms, "skills")
        all_known = all_defined | all_synonyms

        # schemaì˜ relationsì—ì„œ ì°¸ì¡° ì²´í¬
        relations = schema.get("relations", {})
        for rel_type, rel_info in relations.items():
            examples = rel_info.get("examples", [])
            for example in examples:
                if isinstance(example, list):
                    for item in example:
                        if item not in all_known:
                            report.add_issue(
                                severity="info",
                                category="broken",
                                message=f"'{item}'ì´ relations ì˜ˆì‹œì— ìˆì§€ë§Œ ì •ì˜ë˜ì§€ ì•ŠìŒ",
                                location=f"schema.yaml/relations/{rel_type}",
                            )

    def _check_missing_synonyms(
        self,
        schema: dict,
        synonyms: dict,
        report: ValidationReport,
    ) -> None:
        """ë™ì˜ì–´ ëˆ„ë½ ê²€ì‚¬: synonymsì— ìˆì§€ë§Œ schemaì— ì—†ëŠ” ìŠ¤í‚¬"""
        # ìŠ¤í‚¤ë§ˆì—ì„œ ëª¨ë“  ìŠ¤í‚¬ ì¶”ì¶œ
        schema_skills = self._extract_all_skills(schema)

        # ë™ì˜ì–´ì˜ canonical ì¶”ì¶œ
        skill_synonyms = synonyms.get("skills", {})
        canonical_set = set()

        for main_term, info in skill_synonyms.items():
            if isinstance(info, dict):
                canonical = info.get("canonical", main_term)
                canonical_set.add(canonical)

        # ì°¨ì§‘í•©: synonymsì— canonicalë¡œ ìˆì§€ë§Œ schemaì— ì—†ëŠ” ìŠ¤í‚¬
        missing_in_schema = canonical_set - schema_skills

        for skill in sorted(missing_in_schema):
            report.add_issue(
                severity="info",
                category="missing",
                message=f"'{skill}'ì´ synonyms.yamlì— ìˆì§€ë§Œ schema.yaml ê³„ì¸µì— ì—†ìŠµë‹ˆë‹¤",
                location="synonyms.yaml/skills",
            )

    def _extract_all_skills(self, schema: dict) -> set[str]:
        """ìŠ¤í‚¤ë§ˆì—ì„œ ëª¨ë“  ìŠ¤í‚¬ ì¶”ì¶œ"""
        skills = set()
        concepts = schema.get("concepts", {})

        # SkillCategoryì—ì„œ ì¶”ì¶œ
        for category in concepts.get("SkillCategory", []):
            if isinstance(category, dict):
                skills.update(category.get("skills", []))
                for sub in category.get("subcategories", []):
                    skills.update(sub.get("skills", []))

        return skills

    def _extract_all_synonym_terms(
        self,
        synonyms: dict,
        category: str,
    ) -> set[str]:
        """ë™ì˜ì–´ì—ì„œ ëª¨ë“  ìš©ì–´ ì¶”ì¶œ (canonical + aliases)"""
        terms = set()
        category_data = synonyms.get(category, {})

        for main_term, info in category_data.items():
            if isinstance(info, dict):
                canonical = info.get("canonical", main_term)
                aliases = info.get("aliases", [])

                terms.add(canonical)
                terms.add(main_term)
                terms.update(aliases)

        return terms


def main() -> int:
    parser = argparse.ArgumentParser(description="ì˜¨í†¨ë¡œì§€ YAML ê²€ì¦")
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥",
    )
    parser.add_argument(
        "--dir",
        type=Path,
        default=None,
        help="ì˜¨í†¨ë¡œì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: src/domain/ontology)",
    )
    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    print("ğŸ” ì˜¨í†¨ë¡œì§€ ê²€ì¦ ì‹œì‘...")

    validator = OntologyValidator(args.dir)
    report = validator.validate_all()
    report.print_summary()

    return 1 if report.has_errors else 0


if __name__ == "__main__":
    sys.exit(main())
